[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/davisyoshida/easy-lora-and-gptq/blob/master/JAX%20%2B%20GPT%20Q%204%20bit%20%2B%20LoRA%20%2B%20ratio%20%2B%20sudden%20drop%20in%20the%20loss%20function.ipynb)

# Important!
This notebook uses an older version of Lorax, the new version is quite a bit simpler to use.

# Training models with JAX + GPT-Q + LoRA
This notebook shows how to combine [Lorax](https://github.com/davisyoshida/lorax) and [JAX-GPTQ](https://github.com/davisyoshida/jax-gptq) for quantizing + finetuning JAX models.
