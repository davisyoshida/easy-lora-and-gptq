[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/davisyoshida/easy-lora-and-gptq/blob/master/JAX_%2B_GPT_Q_4_bit_%2B_LoRA_%2B_ratio_%2B_sudden_drop_in_the_loss_function.ipynb)

# Training models with JAX + GPT-Q + LoRA
This notebook shows how to combine [Lorax](https://github.com/davisyoshida/lorax) and [JAX-GPTQ](https://github.com/davisyoshida/jax-gptq) for quantizing + finetuning JAX models.
